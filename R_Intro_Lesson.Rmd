---
title: "Introduction to R using Yeast RNAseq Metadata"
author: ANGUS
date: June 2019
output:
  html_document:
    theme: readable
    toc: true
    toc_float:
      collapsed: no
      smooth_scroll: yes
      toc_depth: 3
editor_options: 
  chunk_output_type: console
---

## Getting started

Start up a Jetstream m1.medium or larger
[as per Jetstream startup instructions](jetstream/boot.html).

---

### Using RStudio on Jetstream

We will be using R and RStudio on our cloud instances. We have pre-installed RStudio on the workshop image. Start up a Jetstream m1.medium or larger using the ANGUS 2019 image
[as per Jetstream startup instructions](jetstream/boot.html). Connect to your instance.

We will need a password to connect to RStudio. We can set the password to our instance by running the following commands in bash (the password will not be visible on the screen):

```{bash eval = FALSE}
sudo passwd $USER
```

We will also need our instance username to connect to RStudio. To determine what your username is, run: 

```{bash eval=FALSE}
echo My username is $USER
```

Lastly, find the RStudio server interface Web address (by default in port 8787) by running the following command:

```{bash eval = FALSE}
echo http://(hostname):8787/
```

Now go to the web address printed to your terminal in your Web browser and log in with the username and password that you set above. You should see something that looks like:

![](_static/RStudio.png)

where you type your username and the password that you have set. 


### Installing on your own computer:

We will be using R and RStudio in the cloud. To use RStudio on your computer, you can download R and RStudio. If you do not have R and RStudio installed:
- Download R from CRAN:https://cran.r-project.org/
- Go to RStudio download page and install the version that is compatible with your operating system: https://www.rstudio.com/products/rstudio/download/#download
This [link](https://datacarpentry.org/R-ecology-lesson/) provides futher instructions on
installing and setting up R and RStudio on your computer. 

## Introduction to R and RStudio 

R is a programming language and free software environment for statistical computing and
graphics. Many bioinformatics programs are implemented in R. RStudio is a graphical
integrated development environment (IDE) that displays and organizes more information
about R. R is the underlying programming language. Once you start RStudio, you see this
layout (it will be similar either on your instance or on your computer):

![](_static/RStudio_first.png)

Scripts are like a digital lab book. They record everything your run, as well as notes to
yourself about how and why you ran it. To start a new script you can click on the icon
that looks like a page with a '+' underneath File and select -->R script. This generates a
`.R` file. `.R` files are plain text files that use the file extension `.R` so that humans
can remember that the file contains R code. 

![](_static/RStudio_create_R_script.png)

Although scripts are a record of our code, they also include comments about our code. These comments are very important as they remind your future self (and whoever you pass your script) why you did what you did. Think of comments like the notes you take in your lab book when you do experiments. 

![](_static/RStudio_type_script.png)

When you execute a line of your script, it is sent to the console. While the script is a 
permanent record of everything you ran, the console is the engine that runs those things. 
You can run code from a script or the console, but it is only recorded in scripts. 

There are two additional panes in RStudio. The Environment pane records the objects that
are in our current environment, while the Plots/Viewer/Packages/Files/Help pane provides
a space for us to interact with plots and files we create and with built-in help files in
R. 

And now we're ready to start the fun part!

## Basic concepts

### Objects 

An R object is something that you create and assign a value or function to. You do this using the *assignment operator* which is `<-` (NOTE: shortcut Alt + -). For example you can assign a *numeric* value to an object by typing in your script (remember to comment what you are doing):

```{r}
a <- 34  # assign the number 34 to the object a
```

You can also assign a *character* value to an object:
```{r}
b <- 'mouse' # assign the word 'character' to the object b
```

To run a line of code, put your cursor on the line that you want to run and press `Enter+Cmd` or `Enter+Ctrl`. Or select the line and click the button that says `Run` on the right top corner of your script.

![](_static/first_lines.png)

Now check your Console and Environment tabs, you will see that the commands have run and that you have created new objects!

You can do all sorts of stuff with your objects: operations, combinations, use them in functions. Below we show how to perform multiplication using an object. Because `a` stores the value `34`, we can multiply it by 2:

```{r}
a2 <- a*2 # multiply a by 2
```

## Functions and Arguments

Functions are “canned scripts” that automate more complicated sets of commands including operations assignments, etc. Many functions are predefined, or can be made available by importing R packages (more on that later). A function usually takes one or more inputs called arguments. Functions often (but not always) return a value. A typical example would be the function sqrt(). The input (the argument) must be a number, and the return value (in fact, the output) is the square root of that number. Executing a function (‘running it’) is called calling the function. An example of a function call is:

```{r}
sqrt(a) ## calculate the square root of a
```

Here, the value of a is given to the sqrt() function, the sqrt() function calculates the square root, and returns the value which is then assigned to the object b. This function is very simple, because it takes just one argument.

The return ‘value’ of a function need not be numerical (like that of sqrt()), and it also does not need to be a single item: it can be a set of things, or even a dataset. We’ll see that when we read data files into R.

Arguments can be anything, not only numbers or filenames, but also other objects. Exactly what each argument means differs per function, and must be looked up in the documentation (see below). Some functions take arguments which may either be specified by the user, or, if left out, take on a default value: these are called options. Options are typically used to alter the way the function operates, such as whether it ignores ‘bad values’, or what symbol to use in a plot. However, if you want something specific, you can specify a value of your choice which will be used instead of the default.

Let’s try a function that can take multiple arguments: round().

```{r}
round(3.141592) ## round number
```

Arguments are the 'conditions' of a function. For example, the function `round()` has an argument to determine the number of decimals, and its default in R is 0. Here, we’ve called round() with just one argument, 3.14159, and it has returned the value 3. That’s because the default is to round to the nearest whole number. If we want more digits we can see how to do that by getting information about the round function. We can use args(round) to find what arguments it takes, or look at the help for this function using ?round.

```{r}
args(round) ## show the arguments of the function 'round'
?round ## shows the information about 'round'
```

We can change this to two decimals by changing the `digits` argument:
 
```{r eval = FALSE}
round(3.141592, digits = 2)
```

Note that we do not need to specify the name of the argument as R detects this by the position within the function:

```{r eval = FALSE}
round(3.141592, 2)
```

But you can change the order of the arguments if the arguments are named:

```{r eval = FALSE}
round(digits = 2, x= 3.141592)
```

It's best practice to put the non-optional arguments (the data that you want the function
to work on) first, and then specify the names of all optional arguments. This helps other 
to interpret your code more easily.

## Vectors

A vector is the most common and basic data type in R, and is pretty much the workhorse of R. A vector is composed by a series of values, which can be either numbers or characters. We can assign a series of values to a vector using the c() function.

```{r}
yeast_strain <- c('WT','snf2') 
concentration <- c(43.903, 47.871)
```

There are many functions to inspect a vector and get information about its contents: 

```{r eval = FALSE}
length(yeast_strain) # number of elements in a vector
class(concentration) # type of object b
str(yeast_strain) # inspect the structure of a
```

We can also combine multiple vectors:

```{r}
yeast_strain_concentration <- c(yeast_strain, concentration) # combine two vectors
```

### Data types

An **atomic vector** is the simplest R data type, and it is a vector of a single type. The 6 main atomic vector types that R uses are:

**`'character'`** letters or words
**`'numeric'`** (or `double`) for numbers
**`'logical'`** for `TRUE` and `FALSE` (booleans)
**`'integer'`** for integer numbers (e.g., `2L`, the `L` indicates to R that it’s an integer)
**`'complex'`** to represent complex numbers with real and imaginary parts, for example `2 + 4i`
**`'raw'`** for bitstreams that we will not use or discuss further
**`factor`** represents categorical data (more below!)

You can check the type of vecor you are using with the `typeof()` function.

```{r}
typeof(concentration)
```

R uses many **data structures**, the main ones are:

**`vector`** contain elements of the same type in one dimension 
**`list`** can contain elements of different types and multiple data structures
**`data.frame`** contains rows and columns. Columns can contain different types from other columns.
**`matrix`** with rows and columns that are of the same type
**`array`** stores data in more than 2 dimensions

NOTE: Objects of different types get converted into a single type. This is called **coercion** and it follows a hierarchy: 

logical → numeric → character ← logical


We will use `vectors`, `matrices`, `data.frames`, and `factors` today.

## Subsetting

We can extract values from a vector based on position or conditions: this is called **subsetting**. One way to subset in R is to use `[]`. Indices start at 1.

```{r eval = FALSE}
strains <-  c('WT', 'snf2', 'snf1', 'snf1_snf2') 
strains[2] # subsets the second element
strains[c(2,3)] # subsets the second and third elements
more_strains <- strains[c(1, 2, 3, 1, 4, 3)] # to create an object with more elements than tha original one
more_strains
```

#### Conditional subsetting

We can also subset based on **conditions**, using a logical vector with `TRUE` and `FALSE` or with *operators*:

```{r eval = FALSE}
strains[c(TRUE, FALSE, FALSE, TRUE)] 
concentration >= 43
concentration > 40
concentration < 47
concentration <= 47
concentration[ concentration < 45 | concentration > 47] # | is OR
concentration[ concentration < 45 & concentration == 47] # & is AND , == is mathematical 'equal'
more_strains[more_strains %in% strains]
```

## Missing data

As R was designed to analyze datasets, it includes the concept of missing data (which is
uncommon in other programming languages). Missing data are represented in vectors as NA.

There are in-built functions and arguments to deal with missing data. For example, this
vector contains missing data:

```{r eval = FALSE}
concentration <- c(43.903, 47.871, NA, 48.456, 53.435)
```

```{r}
mean(concentration, na.rm = TRUE) # mean of concentration removing your NA
concentration[!is.na(concentration)] # extract all elements that are NOT NA
na.omit(concentration) # returns a 'numeric' atomic vector with incomplete cases removed
concentration[complete.cases(concentration)] # returns a 'numeric' atomic vector with elements that are complete cases
```

Note, if your data includes missing values, you can code them as blanks (""), or as "NA"
before reading them into R. 

## Factors

Factors are categorical data, stored as integers (numbers) and associated with labels that can be ordered or unordered. This allows doing cool stuff with the data such as count factors, group by certain factors, etc. Once created, factors can only contain a pre-defined set of values, known as `levels`, which R sorts by default in alphabetical order. 

```{r eval = FALSE}
strains <-  factor(c('WT', 'snf2', 'snf1', 'snf1_snf2')) # We make our strains object a factor
class(strains)
nlevels(strains)
strains # R orders alphabetically
strains <- factor(strains, levels = c('WT', 'snf1', 'snf2', 'snf1_snf2')) # we reorder them as we want them
strains 
```

We convert objects using `as.XXX` functions:

```{r eval = FALSE}
strains <- as.character(strains)
class(strains)
strains <- as.factor(strains)
class(strains)
```

And we can also **rename factors** based on position:

```{r eval = FALSE}
levels(strains)[4] <- 'wild_type'
```

# Starting with tabular data

This tutorial is a continuation from our *salmon* lesson- we are using the datasets present in the European Nucleotide Archive dataset PRJEB5348. This is an RNA-seq experiment using comparing two yeast strains, snf2 and WT. The datasets were compared to test the underlying distribution of RNA-seq data, and to test which differential expression programs work best. They sequenced 96 samples in 7 different lanes, with 45 wt and 45 mut strains. Thus, there are 45 biological replicates and 7 technical replicates present, with a total of 672 samples, but we'll use 6 of them! :) 

We will get the information about the RNA quality and quantity that the authors employed in their library prep, and we will explore how the authors made their data avaialble and 'linkable' between technical and biological replicates.

We are going to explore those datasets using RStudio, combining a both base R and an umbrella package called *tidyverse*. 

We are going to first make a directory called 'data' where we are going to store our raw data for analysis using the Terminal, from either Atmosphere or RStudio (tab next to Console). 

```{bash eval=FALSE}
mkdir R/data
```

```{r echo = FALSE}
devtools::install_github("hadley/tidyverse")
library('tidyverse')
```


First we are going to read the files from a url and assign that to experiment_info, using `read_tsv`:

```{r}
experiment_info <- read_tsv(file = 'https://osf.io/pzs7g/download/')
```

`tidyverse` works with 'tibbles', which are like data frames where columns with `characters` are never converted into `factors`. `tidyverse` tibbles are also *parsed* with column specifications: R 'interprets' the data on each column and tells us what class of object they are. We also have a look at it using some exploratory functions:

```{r eval = FALSE}
class(experiment_info) # type of object that sample_details is
dim(experiment_info) # dimensions
summary(experiment_info) # summary stats
head(experiment_info) # shows the first 6 rows and all columns
tail(experiment_info) # last 6 rows and all columns
str(experiment_info) # structure
```

What do you notice? The last 4 columns are empty. We can get rid of them by subsetting, and having a look that we have done things correctly:

```{r eval = FALSE}
sum(is.na(experiment_info$X10)) # adds how many NAs the column X10 has so that you know all your rows are NAs (or not!)
experiment_info <- experiment_info[ ,1:9] # subset all rows and columns 1 to 8
dim(experiment_info) # dimensions
summary(experiment_info) # summary stats
head(experiment_info) # shows the first 6 rows and all columns
tail(experiment_info) # last 6 rows and all columns
str(experiment_info) # structure
```

The 9th column has no name, but in tidyverse we can change this using `rename`:

```{r eval = FALSE}
experiment_info <- rename(experiment_info, units = X9)
```

# Manipulating data with **dplyr**

We can now explore this table and reshape it using `dplyr`. We will cover in this lesson:

` %>% `: pipes, they allow 'concatenating' functions

`select()`: subsets columns

`filter()`: subsets rows on conditions

`mutate()`: create new columns using information from other columns

`group_by()` and `summarize()`: create summary statistics on grouped data

`arrange()`: sort results

`count()`: counts discrete values

## Selecting columns and filtering rows

We have now a table with many columns- are all the columns useful to you? We can select columns using `select`, which requires as *arguments* the names of the colums that you want to keep:

```{r eval = FALSE}
select(experiment_info, Sample, Yeast Strain, Nucleic Acid Conc., Sample, 260/280, Total RNA)
```
What happened? There is a space that R cannot deal well with- we can help R by adding back commas around the `name of the column`. These tell R `this is a word`:

```{r eval = FALSE}
select(experiment_info, Sample, `Yeast Strain`, `Nucleic Acid Conc.`, `260/280`, `Total RNA`)
```

so let's store that in `experiment_info` together with A260 and A280: 

```{r eval = FALSE}
experiment_info <- select(experiment_info, Sample, `Yeast Strain`, `Nucleic Acid Conc.`, A260, A280, `260/280`, `Total RNA`)
```

**NOTE**: When choosing names from cloumns, make sure that you choose something simple, all lowercase, all uppercase, or CamelCase. Having spaces in column names is not a good idea!

We select all columns *except for* by using '-' before the name of the columns we do not want to include, for example all columns except for A260 and A280:

```{r eval = FALSE}
select(experiment_info, -A260, -A280)
```

We can also `filter` rows based on conditions in a column:

```{r eval = FALSE}
filter(experiment_info, `Nucleic Acid Conc.` > 1500)
```

### Exercise 1 
>Select the columns Sample, Yeast Strain, A260 and A280 and assign that to a new object called experiment_data. 

<details>
  <summary><strong><font color="#6B33FF">Solution #1</font></strong></summary>
```{r exercise1, eval = FALSE, foldcode=TRUE}
experiment_data <-  select(experiment_info, Sample, `Yeast Strain`, A260, A280)
```
</details>

### Exercise 2   
>Filter rows for only WT strains that had more than 1500 ng/uL concentration and make a new tibble called wild_type.

<details>
  <summary><strong><font color="#6B33FF">Solution #2</font></strong></summary>
```{r exercise2, eval = FALSE, foldcode=FALSE}
  wild_type <- filter(experiment_info, `Yeast Strain` %in% 'WT' & `Nucleic Acid Conc.` > 1500)
```
</details>


## Pipes

What if we want to `select` and `filter` at the same time? We use %>% (pipes) for that. Pipes are  available via the `magrittr` package, installed automatically with `dplyr`. If you use RStudio, you can type the pipe with `Ctrl + Shift + M` if you have a PC or `Cmd + Shift + M` if you have a Mac.

We can combine the characteristics from Exercise 1 and 2 using pipes `%>%` :

```{r eval = FALSE}
experiment_info_wt <- experiment_info %>% 
  filter(`Yeast Strain` %in% 'WT' & `Nucleic Acid Conc.` > 1500) %>% 
  select(Sample, `Yeast Strain`, A260, A280)
```

### Exercise 3  
>Using pipes, subset experiment_info to include all the samples that had a concentration less than 1500 and  where total RNA was more or equal than 40 ug and retain only the columns that tell you the sample, yeast strain, nucleic acid concentration and total RNA. Assign that to a new table called samples_sequenced.

<details>
  <summary><strong><font color="#6B33FF">Solution #3</font></strong></summary>
```{r exercise3, eval = FALSE}
samples_sequenced <- experiment_info %>% 
  filter(`Nucleic Acid Conc.` < 1500 & `Total RNA` >= 40) %>% 
  select(Sample, `Yeast Strain`,`Nucleic Acid Conc.`,`Total RNA`)
```
</details>

## Mutate

What if I want to create new columns? I use the function `mutate` for this. Let's convert our units into micrograms/microliter:

```{r eval = FALSE}
experiment_info %>% 
  mutate(concentration_ug_uL = `Nucleic Acid Conc.` / 1000)
```

Or create more than one column! And pipe that into head so that we have a peep:

```{r eval = FALSE}
experiment_info %>% 
  mutate(concentration_ug_uL = `Nucleic Acid Conc.` / 1000,
          half_concentration = concentration_ug_uL / 1000) %>% 
  head()
```

### Exercise 4  
>Create a new table called library_start that includes the columns sample, yeast strain and two new columns called RNA_100 with the calculation of microliters to have 100ng of RNA and another column called water that says how many microliters of water we need to add to that to reach 50uL.

<details>
  <summary><strong><font color="#6B33FF">Solution #4</font></strong></summary>
```{r exercise4, eval = FALSE}
library_start <- experiment_info %>% 
  mutate(RNA_100 = 100/ `Nucleic Acid Conc.`,
          water = 50 - RNA_100) %>% 
  select(Sample, `Yeast Strain`, RNA_100, water)
```
</details>


### Exercise 5  
>Pretty difficult to pipette! Can redo the table considering a 1:10 dilution of your samples? Include the columns of A260 and A280 values in addition to sample, yeast strain, RNA_100 and water. 

<details>
  <summary><strong><font color="#6B33FF">Solution #5</font></strong></summary>
```{r eval = FALSE}
library_start_diluted <-  experiment_info %>% 
  mutate(diluted_RNA = 10/ `Nucleic Acid Conc.`,
          water = 50 - diluted_RNA) %>% 
  select(Sample, `Yeast Strain`, `A260`, `A280`, diluted_RNA, water)
```
</details>

### Exercise 6  
>Based on the tibble library_start_diluted, create a new tibble called `seq_samples` that includes only samples with a A260/A280 ratio of 2.2 or more and that only contains the columns for sample, yeast strain, A260280 ratio, diluted RNA and water. 

<details>
  <summary><strong><font color="#6B33FF">Solution #6</font></strong></summary>
```{r eval = FALSE}
seq_samples <- library_start_diluted %>%
  mutate(A260_A280 = `A260`/`A280`) %>% 
  filter(A260_A280 >= 2.2) %>% 
  select(Sample, `Yeast Strain`, A260_A280, diluted_RNA, water)
```
</details>

## Split-apply-combine

The approach of split-apply-combine allows you to *split* the data into groups, *apply* a function/analysis and then *combine* the results. We can do this usign `group-by()` and `summarize()`. 

`group_by()` takes as *argument* the column names that contain categorical variables that we want to calculate summary stats for. For example, to determine the average RNA concetration per strain:

```{r eval = FALSE}
experiment_info %>% 
  group_by(`Yeast Strain`) %>% 
  summarize(mean_concentration = mean(`Nucleic Acid Conc.`))
```
 
or summarize using more than one column:

```{r eval = FALSE}
experiment_info %>% 
  group_by(`Yeast Strain`) %>% 
  summarize(mean_concentration = mean(`Nucleic Acid Conc.`),
            mean_total_RNA = mean(`Total RNA`))
```

NOTE: Our table does not have missing values. However, we have in-built functions in R that can deal with this. We can filter values that are NOT na:

```{r eval = FALSE}
experiment_info %>% 
  group_by(`Yeast Strain`) %>% 
  summarize(mean_concentration = mean(`Nucleic Acid Conc.`, na.rm = TRUE), # na.rm removes NA values while calculating the mean
            mean_total_RNA = mean(`Total RNA`))

experiment_info %>%  
  filter(!is.na(`Nucleic Acid Conc.`)) %>%   # we filter out the values that are not NAs before we do any calculations
  group_by(`Yeast Strain`) %>%  
  summarize(mean_concentration = mean(`Nucleic Acid Conc.`),
            mean_total_RNA = mean(`Total RNA`))
```

We can now arrange the data in ascending order (default of `arrange()`) or descending using `desc()`:

```{r eval = FALSE}
experiment_info %>% 
  filter(!is.na(`Nucleic Acid Conc.`)) %>%  # we filter out the values that are not NAs before we do any calculations
  group_by(`Yeast Strain`) %>% 
  summarize(mean_concentration = mean(`Nucleic Acid Conc.`),
            mean_total_RNA = mean(`Total RNA`)) %>% 
  arrange(mean_concentration) # arranges our new table in ascending mean concentrations

experiment_info %>% 
  filter(!is.na(`Nucleic Acid Conc.`)) %>%  # we filter out the values that are not NAs before we do any calculations
  group_by(`Yeast Strain`) %>% 
  summarize(mean_concentration = mean(`Nucleic Acid Conc.`),
            mean_total_RNA = mean(`Total RNA`)) %>% 
  arrange(desc(mean_concentration) # arranges our new table in descending mean concentrations
```

Another useful function is `count()` to count categorical values:

```{r eval = FALSE}
experiment_info %>% 
  count(`Yeast Strain`)
```

# Combining Datasets using `join`

In many ocassions we will have more than one table that we need to extract information from. We can easily do this in R using the family of `join` functions. 

We are going to first download extra information about the samples that we are are investigating and assing them to an object called *ena_info*:

```{r}
ena_info <- read_tsv(file = 'https://osf.io/6s4cv/download')
sample_mapping <- read_tsv(file = 'https://osf.io/uva3r/download')
```

### Exercise 7  
>Explore your new dataset ena_info and sample_mapping. What commands can you use?

<details>
  <summary><strong><font color="#6B33FF">Solution #7</font></strong></summary>
```{r eval = FALSE}
head(ena_info)
tail(ena_info)
str(ena_info)
class(ena_info)
dim(ena_info)
summary(ena_info)

# and the same with sample_mapping!
```
</details>

The `join` functions allow you to merge tables considering columns/rows characteristics, so that you can do cool stuff such as (taken from R cheatsheets!):

![](_static/join.png)

We have run accession numbers in both our tibbles `sample_mapping` and `ena_info`. We want now to merge both datasets to link the characteristics present in both tables in one big table that contains everything. We need a column that has the same name in both tables. **Challenge**: which function would you use if the column names where not the same?

```{r}
sample_mapping <- rename(sample_mapping, run_accession = RunAccession) # would rename a column called Sample into sample_number to match with the column sample_number in ena_info
yeast_metadata_right <- right_join(ena_info, sample_mapping, by = "run_accession") # this will join both tables matching rows from experiment_info in ena_info
```

That is a big table! 

### Exercise 8  
>How would you merge both tables so that only the rows that are common between both tables are preserved?

<details>
  <summary><strong><font color="#6B33FF">Solution #8</font></strong></summary>
```{r}
yeast_metadata_inner <- inner_join(ena_info, sample_mapping, by = "run_accession")
yeast_metadata_left <- left_join(ena_info, sample_mapping, by = "run_accession")
```
</details>

We will work from now onwards with the tibble `yeast_metadata_inner`. 

### Exercise 9  
>We do not want all the columns; we want to create a new tibble called `yeast_metadata` that contains only run accession, experiment alias, read count, fastq bytes and md5, lane, yeast strain and biological replicate. Rename the column names so that all of the column names are lower_case (lowercase followed by underscore). And include only data from lane number 1. Use pipes!

<details>
  <summary><strong><font color="#6B33FF">Solution #9</font></strong></summary>
```{r}
yeast_metadata <-  yeast_metadata_inner %>% 
  rename(yeast_strain = Sample, lane = Lane, biol_rep = BiolRep) %>% 
  filter(lane == 1) %>% 
  select(run_accession, experiment_alias, read_count, fastq_bytes, fastq_md5, lane, yeast_strain, biol_rep) 

head(yeast_metadata)
```
</details>  

We also want to create a table called `salmon_samples` that will include our 6 samples that we used in `salmon`, namely samples 'ERR458493','ERR458494','ERR458495','ERR458500','ERR458501'and 'ERR458502'.

```{r eval = FALSE}
samples <- c('ERR458493','ERR458494','ERR458495','ERR458500','ERR458501','ERR458502') # we create a vector that includes the samples that we want to subset
salmon_samples <- yeast_metadata_inner %>% 
  filter(run_accession %in% test$samples) # we filter rows based on these sample names
```

# Making plots with ggplot2

We have learnt how to manipulate datasets and combine them. We do this to have a table that is useful for our purposes, which in many occassions is to produce nice plots :). We are going to see the basics of how plotting happens in R using the package `ggplot2` which is part of `tidyverse`.

The basic *syntax* of ggplot2 is:

```{r eval = FALSE}
ggplot(data = <DATA>, mapping = aes(<MAPPINGS>)) +
  <GEOM_FUNCTION>()
```

We are going to make some simple plots to explore our yeast_metadata tibble. There is A LOT more that can be done, lots of options, etc! This is only a taste for what you can do in `ggplot2`. 

We build plots in 'layers':

```{r eval = FALSE}
ggplot(data = yeast_metadata)
```
binds the plot to a specific data frame using the `data` argument

```{r eval = FALSE}
ggplot(data = yeast_metadata, mapping = aes, mapping = aes(x = read_count, y = fastq_bytes))
```
defines the mapping using `aes` (aesthetics of the plot) by selecting the variables to be plotted and how they will be plotted (e.g. x/y, size, shape, color...)

```{r}
ggplot(data = yeast_metadata, mapping = aes(x = read_count, y = fastq_bytes)) +
  geom_point()
```
which sets what type of plot we want to have (boxplot, lines, bars):

`geom_point()` for scatter plots, dot plots, etc.;

`geom_boxplot()` for boxplots;

`geom_line()` for trend lines, time series, etc.  

We can modify plots to extract more information. We can add transparency:

```{r}
ggplot(data = yeast_metadata, mapping = aes(x = read_count, y = fastq_bytes)) +
  geom_point(alpha = 0.1)
```

or change the color of the points:

```{r}
ggplot(data = yeast_metadata, mapping = aes(x = read_count, y = fastq_bytes)) +
  geom_point(alpha = 0.1, color = "red")
```

Or color each strain differently:

```{r}
ggplot(data = yeast_metadata, mapping = aes(x = read_count, y = fastq_bytes)) +
  geom_point(alpha = 1, aes(color = yeast_strain))
```

We can also specify the color inside the mapping: 

```{r}
ggplot(data = yeast_metadata, mapping = aes(x = read_count, y = fastq_bytes, color = yeast_strain)) +
  geom_point(alpha = 1)
```

or try different geom layers:

```{r}
ggplot(data = yeast_metadata, mapping = aes(x = read_count, y = fastq_bytes, color = yeast_strain)) +
  geom_jitter(alpha = 1)
```

We can use boxplots to see the distribution of reads within strains:

```{r}
ggplot(data = yeast_metadata, mapping = aes(x = yeast_strain, y = read_count)) +
  geom_boxplot()
```
This is useful, but if we add dots to the boxplots we will have a better idea of the number of measurements and their distribution:

```{r}
ggplot(data = yeast_metadata, mapping = aes(x = yeast_strain, y = read_count)) +
  geom_boxplot(alpha = 0.1) +
  geom_jitter(alpha = 1, color = "tomato")
```

### Exercise 10  
>Replace the boxplot with a violin plot.

<details>
  <summary><strong><font color="#6B33FF">Solution #10</font></strong></summary>
```{r}
ggplot(data = yeast_metadata, mapping = aes(x = yeast_strain, y = read_count)) +
  geom_violin(alpha = 0.1) +
  geom_jitter(alpha = 1, color = "tomato")
```
</details>  

### Exercise 11  
>Represent the read_count on log10 scale. Check out `scale_y_log10()`.

<details>
  <summary><strong><font color="#6B33FF">Solution #11</font></strong></summary>
```{r}
ggplot(data = yeast_metadata, mapping = aes(x = yeast_strain, y = read_count)) +
  scale_y_log10() + 
  geom_boxplot(alpha = 0.1) +
  geom_jitter(alpha = 1, color = "tomato")
```
</details>


### Exercise 12  
>Try to make a histogram plot for the read counts, coloring each yeast strain. 

<details>
  <summary><strong><font color="#6B33FF">Solution #12</font></strong></summary>
```{r}
# Basic histogram
ggplot(data = yeast_metadata, aes(x=read_count)) + 
  geom_histogram()

# Change colors
p<-ggplot(data = yeast_metadata, aes(x=read_count)) + 
  geom_histogram(color="black", fill="white")
p

# Change colors based on yeast strain
ggplot(data = yeast_metadata, aes(x=read_count, fill = yeast_strain)) + 
  geom_histogram(color="black")

# Facet based on yeast strain
ggplot(data = yeast_metadata, aes(x=read_count, fill = yeast_strain)) + 
  geom_histogram(color="black") + 
  facet_grid(yeast_strain~.)

# Change to custom colors that are color blind friend
ggplot(data = yeast_metadata, aes(x=read_count, fill = yeast_strain)) + 
  geom_histogram(color="black") + 
  facet_grid(yeast_strain~.) +
  # Add blue and yellow colors that are more colorblind friendly for plotting
  scale_fill_manual(values = c("cornflowerblue", "goldenrod2"))
  

# Density based on yeast strain
ggplot(data = yeast_metadata, aes(x=read_count, fill = yeast_strain)) + 
  facet_grid(yeast_strain~.) + 
  geom_density(alpha = 0.5) +
  scale_fill_manual(values = c("cornflowerblue", "goldenrod2"))

# A white background might be preferable for the yellow color
ggplot(data = yeast_metadata, aes(x=read_count, fill = yeast_strain)) + 
  facet_grid(yeast_strain~.) + 
  geom_density(alpha = 0.5) +
  scale_fill_manual(values = c("cornflowerblue", "goldenrod2")) +
  theme_bw()
```
</details>


### Exercise 13
>What if we want to add the mean read counts in a vertical line?

<details>
  <summary><strong><font color="#6B33FF">Solution #13</font></strong></summary>
```{r}
# To do so, we need to calculate the mean_read_count in a new data frame
mean_yeast_data <- yeast_metadata %>%
  group_by(yeast_strain) %>%
  summarise(mean_read_count = mean(read_count))
mean_yeast_data

# Add the mean read_count with vline
ggplot(data = yeast_metadata, aes(x=read_count, fill = yeast_strain)) + 
  geom_density(alpha = 0.5) + 
  facet_grid(yeast_strain~.) + 
  geom_vline(data = mean_yeast_data, mapping = aes(xintercept = mean_read_count),
             linetype="dashed", size=0.5) +
  theme_bw() +
  scale_fill_manual(values = c("cornflowerblue", "goldenrod2"))
```
</details>

## Acknowledgements

This lesson was inspired by and adapted from the [Data Carpentry Ecology R lessons](https://datacarpentry.org/R-ecology-lesson/index.html)

# More material

There are many amazing resources and cheat sheets to continue learning R, including:  

- [R Cookbook](http://www.cookbook-r.com/)  
- [Data Wrangling Cheat Sheet](https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf)  
- [ggplot](https://www.rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf)  
- [R Colors](http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf)  
- [Software Carpentry R Lesson](http://swcarpentry.github.io/r-novice-gapminder/)
